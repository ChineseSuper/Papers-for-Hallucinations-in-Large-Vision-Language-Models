# Papers for Hallucinations in Large Vision-Language Models
We categorize existing papers according to the definition, evaluation, and mitigation of hallucinations in Large Vision-Language Models(LVLMs). It is worth noting that some papers may exist in multiple categories mentioned above.
<br></br>

## Definitions of Hallucinations in Vision-Language Models
1. Rohrbach A, Hendricks L A, Burns K, et al. [Object hallucination in image captioning](https://arxiv.org/abs/1809.02156)[J]. arXiv preprint arXiv:1809.02156, 2018.

<br></br>

## Evaluation of Hallucinations in Large Vision-Language Models
1. Rohrbach A, Hendricks L A, Burns K, et al. [Object hallucination in image captioning](https://arxiv.org/abs/1809.02156)[J]. arXiv preprint arXiv:1809.02156, 2018.
2. Li Y, Du Y, Zhou K, et al. [Evaluating object hallucination in large vision-language models](https://arxiv.org/abs/2305.10355)[J]. arXiv preprint arXiv:2305.10355, 2023.
3. Hu H, Zhang J, Zhao M, et al. [CIEM: Contrastive Instruction Evaluation Method for Better Instruction Tuning](https://arxiv.org/abs/2309.02301)[J]. arXiv preprint arXiv:2309.02301, 2023.
4. Gunjal A, Yin J, Bas E. [Detecting and preventing hallucinations in large vision language models](https://arxiv.org/abs/2308.06394)[J]. arXiv preprint arXiv:2308.06394, 2023.
5. Wang J, Zhou Y, Xu G, et al. [Evaluation and Analysis of Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2308.15126)[J]. arXiv preprint arXiv:2308.15126, 2023.
6. Liu H, Wan X. [Models See Hallucinations: Evaluating the Factuality in Video Captioning](https://arxiv.org/abs/2303.02961)[J]. arXiv preprint arXiv:2303.02961, 2023.

<br></br>

## Mitigation of Hallucinations in Large Vision-Language Models
1. Biten A F, GÃ³mez L, Karatzas D. [Let there be a clock on the beach: Reducing object hallucination in image captioning]()http://openaccess.thecvf.com/content/WACV2022/html/Biten_Let_There_Be_a_Clock_on_the_Beach_Reducing_Object_WACV_2022_paper.html[C]//Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2022: 1381-1390. (Not for Large Vision-Language Models, only for image caption models)
2. Hu H, Zhang J, Zhao M, et al. [CIEM: Contrastive Instruction Evaluation Method for Better Instruction Tuning](https://arxiv.org/abs/2309.02301)[J]. arXiv preprint arXiv:2309.02301, 2023.
3. Gunjal A, Yin J, Bas E. [Detecting and preventing hallucinations in large vision language models](https://arxiv.org/abs/2308.06394)[J]. arXiv preprint arXiv:2308.06394, 2023.

